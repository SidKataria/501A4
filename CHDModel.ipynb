{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHDModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidKataria/501A4/blob/master/CHDModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47inPEtR9Mk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @author Siddharth Kataria\n",
        "# UCID: 30000880\n",
        "# Fall 2019\n",
        "# CPSC 501\n",
        "# Assignment 4 - Part 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH8ntoYR2UaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypOKj6FB2ZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow_core.python.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05g509c64cO6",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8cbe8349-fe09-4a5c-ff12-f6a645be2fa8"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ef0c7eb0-994d-4900-afe2-a6387b3d813f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ef0c7eb0-994d-4900-afe2-a6387b3d813f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving heart.csv to heart (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQjTxhfS3KZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "6e80533f-7abf-4d31-9275-42eda98462d9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('heart.csv')\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "\n",
        "train = df[msk]\n",
        "test = df[~msk]\n",
        "print(test)\n",
        "print(train)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     row.names  sbp  tobacco   ldl  ...  alcohol age  chd     split\n",
            "0            1  160    12.00  5.73  ...    97.20  52    1 -0.098444\n",
            "3            4  170     7.50  6.41  ...    24.26  58    1 -1.775224\n",
            "7            8  114     4.08  4.59  ...     6.72  58    1 -1.982076\n",
            "11          12  134    14.10  4.44  ...     0.00  40    1  1.534408\n",
            "12          13  118     0.00  1.88  ...     0.00  17    0 -0.720040\n",
            "..         ...  ...      ...   ...  ...      ...  ..  ...       ...\n",
            "442        444  166     6.00  8.80  ...    43.20  52    0  0.114048\n",
            "454        456  146     0.64  4.82  ...     8.23  39    1  0.012528\n",
            "456        458  170     0.40  4.11  ...     2.06  57    0 -0.351867\n",
            "457        459  214     0.40  5.98  ...     0.00  58    0 -0.250826\n",
            "461        463  132     0.00  4.82  ...     0.00  46    1 -0.287198\n",
            "\n",
            "[126 rows x 12 columns]\n",
            "     row.names  sbp  tobacco    ldl  ...  alcohol age  chd     split\n",
            "1            2  144     0.01   4.41  ...     2.06  63    1 -0.742985\n",
            "2            3  118     0.08   3.48  ...     3.81  46    0 -0.274453\n",
            "4            5  134    13.60   3.50  ...    57.34  49    1  0.302101\n",
            "5            6  132     6.20   6.47  ...    14.14  45    0  0.789408\n",
            "6            7  142     4.05   3.38  ...     2.62  38    0 -0.334565\n",
            "..         ...  ...      ...    ...  ...      ...  ..  ...       ...\n",
            "453        455  124     1.60   7.22  ...     0.00  51    1  0.296714\n",
            "455        457  128     2.24   2.83  ...    47.42  27    1 -1.317847\n",
            "458        460  182     4.20   4.41  ...    18.72  52    1 -0.346654\n",
            "459        461  108     3.00   1.59  ...    26.64  55    0 -0.232651\n",
            "460        462  118     5.40  11.61  ...    23.97  40    0  0.091363\n",
            "\n",
            "[336 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu8iKK_z4k9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "test.to_csv('heart_test.csv')\n",
        "train.to_csv('heart_train.csv')\n",
        "files.download('heart_test.csv')\n",
        "files.download('heart_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBL_dCro6CGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_path = \"heart_train.csv\"\n",
        "test_file_path = \"heart_test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwxUdDyv7BRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRYG_n-7G-T",
        "colab_type": "text"
      },
      "source": [
        "Checking the csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAhPC9o57EKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "40e5ad1e-174c-46be-d6e9-4a9606d6899a"
      },
      "source": [
        "!head {train_file_path}\n",
        "!head {test_file_path}"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",row.names,sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd,split\n",
            "1,2,144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1,-0.7429847363176832\n",
            "2,3,118,0.08,3.48,32.28,Present,52,29.14,3.81,46,0,-0.27445289166690107\n",
            "4,5,134,13.6,3.5,27.78,Present,60,25.99,57.34,49,1,0.302100559068745\n",
            "5,6,132,6.2,6.47,36.21,Present,62,30.77,14.14,45,0,0.789408477831719\n",
            "6,7,142,4.05,3.38,16.2,Absent,59,20.81,2.62,38,0,-0.3345650311190216\n",
            "8,9,114,0.0,3.83,19.4,Present,49,24.86,2.49,29,0,-1.1871482180668584\n",
            "9,10,132,0.0,5.8,30.96,Present,69,30.11,0.0,53,1,2.1592838137006525\n",
            "10,11,206,6.0,2.95,32.27,Absent,72,26.81,56.06,60,1,0.9751351390166565\n",
            "13,14,132,0.0,1.87,17.21,Absent,49,23.63,0.97,15,0,1.4708476054596495\n",
            ",row.names,sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd,split\n",
            "0,1,160,12.0,5.73,23.11,Present,49,25.3,97.2,52,1,-0.09844384692212212\n",
            "3,4,170,7.5,6.41,38.03,Present,51,31.99,24.26,58,1,-1.7752242229959088\n",
            "7,8,114,4.08,4.59,14.6,Present,62,23.11,6.72,58,1,-1.9820763614832215\n",
            "11,12,134,14.1,4.44,22.39,Present,65,23.09,0.0,40,1,1.5344080216425162\n",
            "12,13,118,0.0,1.88,10.05,Absent,59,21.57,0.0,17,0,-0.7200404143863005\n",
            "19,20,124,14.0,6.23,35.96,Present,45,30.09,0.0,59,1,-0.6906912161138123\n",
            "23,24,138,0.6,3.81,28.66,Absent,54,28.7,1.46,58,0,-0.3399319222330291\n",
            "27,28,145,9.1,5.24,27.55,Absent,59,20.96,21.6,61,1,-1.1158652294588185\n",
            "47,48,116,1.91,7.56,26.45,Present,52,30.01,3.6,33,1,0.03318315899161212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3XgIb7z7LaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'chd'\n",
        "LABELS = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlae2y4T7TjQ",
        "colab_type": "text"
      },
      "source": [
        "Reading the csv data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPpULlJp7RLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=10,\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "SELECT_COLUMNS = ['sbp','tobacco','ldl','adiposity','famhist', 'typea','obesity','alcohol','age','chd']\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "raw_test_data = get_dataset(test_file_path, select_columns=SELECT_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkQ2Sz_g7W81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcLOErb-7dcq",
        "colab_type": "text"
      },
      "source": [
        "Checking training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS0DWFnd7ZkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f53f7586-541c-40cc-804b-dcdde0aad90f"
      },
      "source": [
        "print(\"Train: \")\n",
        "show_batch(raw_train_data)\n",
        "print(\"Test: \")\n",
        "show_batch(raw_test_data)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: \n",
            "sbp                 : [126 164 150 142 118 164 116 174 178 108]\n",
            "tobacco             : [ 0.   12.    0.    0.    1.05 13.02 31.2   2.02  0.95  0.8 ]\n",
            "ldl                 : [5.98 3.91 4.99 4.19 3.16 6.26 3.17 6.57 4.75 2.47]\n",
            "adiposity           : [29.06 19.59 27.73 18.04 12.98 29.38 14.99 31.9  21.06 17.53]\n",
            "famhist             : [b'Present' b'Absent' b'Absent' b'Absent' b'Present' b'Present' b'Absent'\n",
            " b'Present' b'Absent' b'Absent']\n",
            "typea               : [56 51 57 56 46 47 47 50 49 47]\n",
            "obesity             : [25.39 23.44 30.92 23.65 22.09 22.75 19.4  28.75 23.74 22.18]\n",
            "alcohol             : [11.52 19.75  8.33 20.78 16.35 37.03 49.06 11.83 24.69  0.  ]\n",
            "age                 : [64 39 24 42 31 54 59 64 61 55]\n",
            "Test: \n",
            "sbp                 : [122 142 118 103 124 174 101 142 142 148]\n",
            "tobacco             : [0.   0.28 0.   0.03 6.   9.45 0.48 0.   7.44 0.  ]\n",
            "ldl                 : [3.08 1.8  1.88 4.21 5.21 5.13 7.26 3.54 5.52 5.32]\n",
            "adiposity           : [16.3  21.03 10.05 18.96 33.02 35.54 13.   16.64 33.97 26.71]\n",
            "famhist             : [b'Absent' b'Absent' b'Absent' b'Absent' b'Present' b'Absent' b'Absent'\n",
            " b'Absent' b'Absent' b'Present']\n",
            "typea               : [43 57 59 48 64 55 50 58 47 52]\n",
            "obesity             : [22.13 23.65 21.57 22.94 29.37 30.71 19.82 25.97 29.29 32.21]\n",
            "alcohol             : [ 0.    2.93  0.    2.62  7.61 59.79  5.19  8.36 24.27 32.78]\n",
            "age                 : [16 33 17 18 58 53 16 27 54 27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b9O1nT27f64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, labels_batch = next(iter(raw_train_data)) \n",
        "test_batch, labels_batch = next(iter(raw_test_data)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSp70XOW7xox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=-1), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCdNoBZ57z3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euUNeoIO75Vd",
        "colab_type": "text"
      },
      "source": [
        "Putting in training and test data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5fDd6Vc73Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['sbp','tobacco','ldl','adiposity', 'typea','obesity','alcohol','age']\n",
        "FEATURES = 8\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Exq81_8BZ0",
        "colab_type": "text"
      },
      "source": [
        "Checking packed training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1_qRIuZ78eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "abd240a7-3986-488b-a404-3b63a8ed53b4"
      },
      "source": [
        "print(\"Train: \")\n",
        "show_batch(packed_train_data)\n",
        "print(\"Test: \")\n",
        "show_batch(packed_test_data)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: \n",
            "famhist             : [b'Absent' b'Present' b'Present' b'Absent' b'Absent' b'Present' b'Absent'\n",
            " b'Present' b'Absent' b'Present']\n",
            "numeric             : [[128.     2.24   2.83  26.48  48.    23.96  47.42  27.  ]\n",
            " [176.     6.     3.98  17.2   52.    21.07   4.11  61.  ]\n",
            " [162.     7.4    8.55  24.65  64.    25.71   5.86  58.  ]\n",
            " [110.    12.16   4.99  28.56  44.    27.14  21.6   55.  ]\n",
            " [122.     0.     3.37  16.1   67.    21.06   0.    32.  ]\n",
            " [136.     3.96   2.76  30.28  50.    34.42  18.51  38.  ]\n",
            " [158.     1.02   6.33  23.88  66.    22.13  24.99  46.  ]\n",
            " [136.     3.99   2.58  16.38  53.    22.41  27.67  36.  ]\n",
            " [148.     4.5   10.49  33.27  50.    25.92   2.06  53.  ]\n",
            " [122.     0.     5.75  30.9   46.    29.01   4.11  42.  ]]\n",
            "Test: \n",
            "famhist             : [b'Absent' b'Absent' b'Present' b'Absent' b'Absent' b'Present' b'Absent'\n",
            " b'Present' b'Absent' b'Absent']\n",
            "numeric             : [[130.     0.56   3.3   30.86  49.    27.52  33.33  45.  ]\n",
            " [138.    12.     5.13  28.34  59.    24.49  32.81  58.  ]\n",
            " [158.     4.     4.18  28.61  42.    25.11   0.    60.  ]\n",
            " [144.     0.76  10.53  35.66  63.    34.35   0.    55.  ]\n",
            " [158.    13.5    5.04  30.79  54.    24.79  21.5   62.  ]\n",
            " [136.     0.4    3.91  21.1   63.    22.3    0.    56.  ]\n",
            " [160.     0.     2.42  34.46  48.    29.83   1.03  61.  ]\n",
            " [132.     6.     5.97  25.73  66.    24.18 145.29  41.  ]\n",
            " [158.     6.17   8.12  30.75  46.    27.84  92.62  48.  ]\n",
            " [144.     6.75   5.45  29.81  53.    25.62  26.23  43.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW38qWVF8L9K",
        "colab_type": "text"
      },
      "source": [
        "Creating Branches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h762VcW58JeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, label_batch = next(iter(packed_train_data))\n",
        "test_batch, label_batch = next(iter(packed_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxPgQzGn8RjU",
        "colab_type": "text"
      },
      "source": [
        "Checking normalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-o0ZSlM8OJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c79d52a0-7344-4ad8-9343-9afa0db7a584"
      },
      "source": [
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sbp</th>\n",
              "      <th>tobacco</th>\n",
              "      <th>ldl</th>\n",
              "      <th>adiposity</th>\n",
              "      <th>typea</th>\n",
              "      <th>obesity</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>336.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>137.803571</td>\n",
              "      <td>3.616012</td>\n",
              "      <td>4.681280</td>\n",
              "      <td>24.957679</td>\n",
              "      <td>53.285714</td>\n",
              "      <td>25.975506</td>\n",
              "      <td>17.561815</td>\n",
              "      <td>42.288690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.403617</td>\n",
              "      <td>4.625679</td>\n",
              "      <td>2.103097</td>\n",
              "      <td>7.671883</td>\n",
              "      <td>9.927284</td>\n",
              "      <td>4.098951</td>\n",
              "      <td>24.320584</td>\n",
              "      <td>14.427896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>6.740000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>17.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>124.000000</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>3.195000</td>\n",
              "      <td>19.460000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>22.940000</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>30.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>134.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.235000</td>\n",
              "      <td>25.700000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>25.740000</td>\n",
              "      <td>7.780000</td>\n",
              "      <td>44.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>146.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>30.530000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>28.347500</td>\n",
              "      <td>24.322500</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>218.000000</td>\n",
              "      <td>31.200000</td>\n",
              "      <td>15.330000</td>\n",
              "      <td>42.170000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>46.580000</td>\n",
              "      <td>147.190000</td>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              sbp     tobacco         ldl  ...     obesity     alcohol         age\n",
              "count  336.000000  336.000000  336.000000  ...  336.000000  336.000000  336.000000\n",
              "mean   137.803571    3.616012    4.681280  ...   25.975506   17.561815   42.288690\n",
              "std     20.403617    4.625679    2.103097  ...    4.098951   24.320584   14.427896\n",
              "min    102.000000    0.000000    0.980000  ...   17.750000    0.000000   15.000000\n",
              "25%    124.000000    0.077500    3.195000  ...   22.940000    0.637500   30.750000\n",
              "50%    134.000000    2.000000    4.235000  ...   25.740000    7.780000   44.000000\n",
              "75%    146.000000    5.400000    5.800000  ...   28.347500   24.322500   55.000000\n",
              "max    218.000000   31.200000   15.330000  ...   46.580000  147.190000   64.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVZ7WJXY8UBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD-2VR3d8WfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUVLsZHK8fGU",
        "colab_type": "text"
      },
      "source": [
        "Final normalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5T2FKff8Yr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e54cee10-fdbb-4c72-856a-3e526006d9b8"
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(8,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7fcd5ddea840>, mean=array([137.804,   3.616,   4.681,  24.958,  53.286,  25.976,  17.562,\n",
              "        42.289]), std=array([20.404,  4.626,  2.103,  7.672,  9.927,  4.099, 24.321, 14.428])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLcIdRDU8cvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "34631222-379a-4f8c-86e5-0cb3485af3e4"
      },
      "source": [
        "train_batch['numeric']\n",
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(train_batch).numpy()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.382,  0.792, -0.533, -0.217, -3.353,  0.201,  1.411,  1.089],\n",
              "       [ 0.696,  1.402,  0.014, -0.04 ,  1.18 ,  0.057,  0.287,  1.02 ],\n",
              "       [-0.873, -0.782, -1.075, -1.082, -0.734, -1.419, -0.722, -1.753],\n",
              "       [-0.579,  0.04 , -0.381,  0.891,  0.374,  1.111, -0.722, -0.852],\n",
              "       [-0.48 , -0.773,  1.683,  0.419,  1.18 ,  0.065, -0.24 , -1.268],\n",
              "       [ 0.108, -0.652,  0.418,  1.099,  0.475,  0.296, -0.722,  0.881],\n",
              "       [-0.088, -0.782,  0.152,  0.342, -0.432,  0.394, -0.662, -0.228],\n",
              "       [ 2.754, -0.23 ,  1.05 ,  1.163,  1.583,  0.818, -0.722, -0.089],\n",
              "       [-0.284,  0.792, -0.552, -1.646,  0.676, -1.585, -0.637,  0.95 ],\n",
              "       [ 1.186, -0.782,  0.194, -0.047,  1.079,  0.179, -0.565, -1.683]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgadMjCV8y7a",
        "colab_type": "text"
      },
      "source": [
        "Categorizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "484pHx7I8lZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "63b91222-9e95-43d4-ea9a-a73864d1f685"
      },
      "source": [
        "CATEGORIES = {\n",
        "    'famhist': ['Present', 'Absent']\n",
        "}\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))\n",
        "categorical_columns"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='famhist', vocabulary_list=('Present', 'Absent'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ay56z481Mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb01168a-4a1c-4d96-a137-d8590836730b"
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(train_batch).numpy()[0])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rmcyeYA834-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi_t0nnG9Bin",
        "colab_type": "text"
      },
      "source": [
        "Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ6t9AaV88GJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d9acb2e-59fa-4697-806f-7e4598e33a0e"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(50, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adamax',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data\n",
        "\n",
        "print(\"--Fit model--\")\n",
        "model.fit(train_data, epochs=500)\n",
        "\n",
        "print(\"--Evaluate model--\")\n",
        "model_loss, model_acc = model.evaluate(test_data, verbose=2)\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\n",
        "print(f\"Model Accuray: {model_acc*100:.1f}%\\n\")\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "for prediction, hasCHD in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  print(\"Predicted CHD Diagnose Rate: {:.2%}\".format(prediction[0]),\n",
        "        \"    | Actual outcome: \",\n",
        "        (\"Has CHD\" if bool(hasCHD) else \"no CHD\"))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Fit model--\n",
            "Epoch 1/500\n",
            "34/34 [==============================] - 1s 31ms/step - loss: 0.6603 - accuracy: 0.6131\n",
            "Epoch 2/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.6548\n",
            "Epoch 3/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6726\n",
            "Epoch 4/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.6964\n",
            "Epoch 5/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.6845\n",
            "Epoch 6/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7292\n",
            "Epoch 7/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7321\n",
            "Epoch 8/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7083\n",
            "Epoch 9/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7500\n",
            "Epoch 10/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7470\n",
            "Epoch 11/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7470\n",
            "Epoch 12/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7560\n",
            "Epoch 13/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7232\n",
            "Epoch 14/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7560\n",
            "Epoch 15/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7679\n",
            "Epoch 16/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7619\n",
            "Epoch 17/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7708\n",
            "Epoch 18/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7411\n",
            "Epoch 19/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7560\n",
            "Epoch 20/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7560\n",
            "Epoch 21/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7679\n",
            "Epoch 22/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7768\n",
            "Epoch 23/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7679\n",
            "Epoch 24/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7470\n",
            "Epoch 25/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7649\n",
            "Epoch 26/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7827\n",
            "Epoch 27/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7649\n",
            "Epoch 28/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7857\n",
            "Epoch 29/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7798\n",
            "Epoch 30/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7738\n",
            "Epoch 31/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7857\n",
            "Epoch 32/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7708\n",
            "Epoch 33/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7976\n",
            "Epoch 34/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7827\n",
            "Epoch 35/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7619\n",
            "Epoch 36/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7708\n",
            "Epoch 37/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7768\n",
            "Epoch 38/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7917\n",
            "Epoch 39/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7976\n",
            "Epoch 40/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7738\n",
            "Epoch 41/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7976\n",
            "Epoch 42/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7917\n",
            "Epoch 43/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7827\n",
            "Epoch 44/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7917\n",
            "Epoch 45/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7708\n",
            "Epoch 46/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8036\n",
            "Epoch 47/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7857\n",
            "Epoch 48/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7857\n",
            "Epoch 49/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8006\n",
            "Epoch 50/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7798\n",
            "Epoch 51/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8125\n",
            "Epoch 52/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8065\n",
            "Epoch 53/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7976\n",
            "Epoch 54/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7917\n",
            "Epoch 55/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8006\n",
            "Epoch 56/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7798\n",
            "Epoch 57/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8095\n",
            "Epoch 58/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8036\n",
            "Epoch 59/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8244\n",
            "Epoch 60/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8095\n",
            "Epoch 61/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8095\n",
            "Epoch 62/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8214\n",
            "Epoch 63/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7887\n",
            "Epoch 64/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8036\n",
            "Epoch 65/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8155\n",
            "Epoch 66/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8095\n",
            "Epoch 67/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8333\n",
            "Epoch 68/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8155\n",
            "Epoch 69/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8125\n",
            "Epoch 70/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8304\n",
            "Epoch 71/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8185\n",
            "Epoch 72/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8185\n",
            "Epoch 73/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8155\n",
            "Epoch 74/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8333\n",
            "Epoch 75/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8125\n",
            "Epoch 76/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8185\n",
            "Epoch 77/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8155\n",
            "Epoch 78/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8095\n",
            "Epoch 79/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8095\n",
            "Epoch 80/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8304\n",
            "Epoch 81/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8363\n",
            "Epoch 82/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8185\n",
            "Epoch 83/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8423\n",
            "Epoch 84/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8244\n",
            "Epoch 85/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8363\n",
            "Epoch 86/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8304\n",
            "Epoch 87/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8423\n",
            "Epoch 88/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8274\n",
            "Epoch 89/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8333\n",
            "Epoch 90/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8244\n",
            "Epoch 91/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8363\n",
            "Epoch 92/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8393\n",
            "Epoch 93/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8185\n",
            "Epoch 94/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8423\n",
            "Epoch 95/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8512\n",
            "Epoch 96/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8482\n",
            "Epoch 97/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8512\n",
            "Epoch 98/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8512\n",
            "Epoch 99/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8512\n",
            "Epoch 100/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8363\n",
            "Epoch 101/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8274\n",
            "Epoch 102/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8333\n",
            "Epoch 103/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8542\n",
            "Epoch 104/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8393\n",
            "Epoch 105/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8452\n",
            "Epoch 106/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8214\n",
            "Epoch 107/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8393\n",
            "Epoch 108/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8423\n",
            "Epoch 109/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8423\n",
            "Epoch 110/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8274\n",
            "Epoch 111/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8452\n",
            "Epoch 112/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8601\n",
            "Epoch 113/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8393\n",
            "Epoch 114/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8214\n",
            "Epoch 115/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8571\n",
            "Epoch 116/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8423\n",
            "Epoch 117/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8452\n",
            "Epoch 118/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8512\n",
            "Epoch 119/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8274\n",
            "Epoch 120/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8333\n",
            "Epoch 121/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8720\n",
            "Epoch 122/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8601\n",
            "Epoch 123/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8571\n",
            "Epoch 124/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8452\n",
            "Epoch 125/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8393\n",
            "Epoch 126/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8333\n",
            "Epoch 127/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8542\n",
            "Epoch 128/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8601\n",
            "Epoch 129/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8720\n",
            "Epoch 130/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8601\n",
            "Epoch 131/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8512\n",
            "Epoch 132/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8690\n",
            "Epoch 133/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8631\n",
            "Epoch 134/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8452\n",
            "Epoch 135/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8690\n",
            "Epoch 136/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8452\n",
            "Epoch 137/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8393\n",
            "Epoch 138/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8512\n",
            "Epoch 139/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8780\n",
            "Epoch 140/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8601\n",
            "Epoch 141/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8333\n",
            "Epoch 142/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8810\n",
            "Epoch 143/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8661\n",
            "Epoch 144/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8333\n",
            "Epoch 145/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8542\n",
            "Epoch 146/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8780\n",
            "Epoch 147/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8482\n",
            "Epoch 148/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8780\n",
            "Epoch 149/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8631\n",
            "Epoch 150/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8512\n",
            "Epoch 151/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8423\n",
            "Epoch 152/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8661\n",
            "Epoch 153/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8512\n",
            "Epoch 154/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8690\n",
            "Epoch 155/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8512\n",
            "Epoch 156/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8571\n",
            "Epoch 157/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8839\n",
            "Epoch 158/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8601\n",
            "Epoch 159/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8661\n",
            "Epoch 160/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8661\n",
            "Epoch 161/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8720\n",
            "Epoch 162/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8661\n",
            "Epoch 163/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8601\n",
            "Epoch 164/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8720\n",
            "Epoch 165/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8661\n",
            "Epoch 166/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8661\n",
            "Epoch 167/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8661\n",
            "Epoch 168/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8899\n",
            "Epoch 169/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8780\n",
            "Epoch 170/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8631\n",
            "Epoch 171/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8631\n",
            "Epoch 172/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8810\n",
            "Epoch 173/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8720\n",
            "Epoch 174/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8542\n",
            "Epoch 175/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8631\n",
            "Epoch 176/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8661\n",
            "Epoch 177/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8899\n",
            "Epoch 178/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8601\n",
            "Epoch 179/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8810\n",
            "Epoch 180/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8929\n",
            "Epoch 181/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8810\n",
            "Epoch 182/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8780\n",
            "Epoch 183/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8690\n",
            "Epoch 184/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8810\n",
            "Epoch 185/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8958\n",
            "Epoch 186/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8750\n",
            "Epoch 187/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8810\n",
            "Epoch 188/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.8750\n",
            "Epoch 189/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8780\n",
            "Epoch 190/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8839\n",
            "Epoch 191/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8631\n",
            "Epoch 192/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8661\n",
            "Epoch 193/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8839\n",
            "Epoch 194/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8810\n",
            "Epoch 195/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8929\n",
            "Epoch 196/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8780\n",
            "Epoch 197/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8720\n",
            "Epoch 198/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8839\n",
            "Epoch 199/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8899\n",
            "Epoch 200/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8899\n",
            "Epoch 201/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9018\n",
            "Epoch 202/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8750\n",
            "Epoch 203/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8810\n",
            "Epoch 204/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8929\n",
            "Epoch 205/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8780\n",
            "Epoch 206/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8988\n",
            "Epoch 207/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8750\n",
            "Epoch 208/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9048\n",
            "Epoch 209/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8810\n",
            "Epoch 210/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8810\n",
            "Epoch 211/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8810\n",
            "Epoch 212/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8839\n",
            "Epoch 213/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8988\n",
            "Epoch 214/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8810\n",
            "Epoch 215/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8958\n",
            "Epoch 216/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8899\n",
            "Epoch 217/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8958\n",
            "Epoch 218/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.9048\n",
            "Epoch 219/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8899\n",
            "Epoch 220/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8810\n",
            "Epoch 221/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8839\n",
            "Epoch 222/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9048\n",
            "Epoch 223/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8810\n",
            "Epoch 224/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8929\n",
            "Epoch 225/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.8988\n",
            "Epoch 226/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8869\n",
            "Epoch 227/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8929\n",
            "Epoch 228/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9018\n",
            "Epoch 229/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.9048\n",
            "Epoch 230/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8958\n",
            "Epoch 231/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8929\n",
            "Epoch 232/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2693 - accuracy: 0.8780\n",
            "Epoch 233/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.9077\n",
            "Epoch 234/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8988\n",
            "Epoch 235/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9048\n",
            "Epoch 236/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8958\n",
            "Epoch 237/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8988\n",
            "Epoch 238/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8810\n",
            "Epoch 239/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8869\n",
            "Epoch 240/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.9107\n",
            "Epoch 241/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8988\n",
            "Epoch 242/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8899\n",
            "Epoch 243/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9077\n",
            "Epoch 244/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8810\n",
            "Epoch 245/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.8929\n",
            "Epoch 246/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8929\n",
            "Epoch 247/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8929\n",
            "Epoch 248/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9107\n",
            "Epoch 249/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.8839\n",
            "Epoch 250/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8780\n",
            "Epoch 251/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9018\n",
            "Epoch 252/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8929\n",
            "Epoch 253/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2419 - accuracy: 0.9048\n",
            "Epoch 254/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8690\n",
            "Epoch 255/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9077\n",
            "Epoch 256/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9107\n",
            "Epoch 257/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.8958\n",
            "Epoch 258/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8929\n",
            "Epoch 259/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.8988\n",
            "Epoch 260/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8869\n",
            "Epoch 261/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9107\n",
            "Epoch 262/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.9018\n",
            "Epoch 263/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8899\n",
            "Epoch 264/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9018\n",
            "Epoch 265/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8929\n",
            "Epoch 266/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9345\n",
            "Epoch 267/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9048\n",
            "Epoch 268/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8780\n",
            "Epoch 269/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8988\n",
            "Epoch 270/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8780\n",
            "Epoch 271/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9048\n",
            "Epoch 272/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.9048\n",
            "Epoch 273/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.8958\n",
            "Epoch 274/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.8929\n",
            "Epoch 275/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9018\n",
            "Epoch 276/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9137\n",
            "Epoch 277/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.8869\n",
            "Epoch 278/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9226\n",
            "Epoch 279/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9137\n",
            "Epoch 280/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9018\n",
            "Epoch 281/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8958\n",
            "Epoch 282/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.8958\n",
            "Epoch 283/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.8988\n",
            "Epoch 284/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.8929\n",
            "Epoch 285/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9077\n",
            "Epoch 286/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9137\n",
            "Epoch 287/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8899\n",
            "Epoch 288/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9196\n",
            "Epoch 289/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9196\n",
            "Epoch 290/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9137\n",
            "Epoch 291/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9167\n",
            "Epoch 292/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9196\n",
            "Epoch 293/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9048\n",
            "Epoch 294/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9077\n",
            "Epoch 295/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9077\n",
            "Epoch 296/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9167\n",
            "Epoch 297/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9077\n",
            "Epoch 298/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9107\n",
            "Epoch 299/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9018\n",
            "Epoch 300/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9226\n",
            "Epoch 301/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2228 - accuracy: 0.9167\n",
            "Epoch 302/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9077\n",
            "Epoch 303/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.9018\n",
            "Epoch 304/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9077\n",
            "Epoch 305/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9077\n",
            "Epoch 306/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9196\n",
            "Epoch 307/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.8958\n",
            "Epoch 308/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9167\n",
            "Epoch 309/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9256\n",
            "Epoch 310/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.8958\n",
            "Epoch 311/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.8988\n",
            "Epoch 312/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9107\n",
            "Epoch 313/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9018\n",
            "Epoch 314/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9167\n",
            "Epoch 315/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9077\n",
            "Epoch 316/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9077\n",
            "Epoch 317/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.8899\n",
            "Epoch 318/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9137\n",
            "Epoch 319/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9226\n",
            "Epoch 320/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9196\n",
            "Epoch 321/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9256\n",
            "Epoch 322/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9107\n",
            "Epoch 323/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9048\n",
            "Epoch 324/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9137\n",
            "Epoch 325/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9167\n",
            "Epoch 326/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9137\n",
            "Epoch 327/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9286\n",
            "Epoch 328/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.8988\n",
            "Epoch 329/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9107\n",
            "Epoch 330/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9077\n",
            "Epoch 331/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9315\n",
            "Epoch 332/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.8958\n",
            "Epoch 333/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8929\n",
            "Epoch 334/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9107\n",
            "Epoch 335/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9286\n",
            "Epoch 336/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9107\n",
            "Epoch 337/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9375\n",
            "Epoch 338/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9077\n",
            "Epoch 339/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.8988\n",
            "Epoch 340/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9196\n",
            "Epoch 341/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9137\n",
            "Epoch 342/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9196\n",
            "Epoch 343/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9167\n",
            "Epoch 344/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9077\n",
            "Epoch 345/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9286\n",
            "Epoch 346/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9226\n",
            "Epoch 347/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9077\n",
            "Epoch 348/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9077\n",
            "Epoch 349/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9226\n",
            "Epoch 350/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9256\n",
            "Epoch 351/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9137\n",
            "Epoch 352/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9375\n",
            "Epoch 353/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9137\n",
            "Epoch 354/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9315\n",
            "Epoch 355/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9077\n",
            "Epoch 356/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9107\n",
            "Epoch 357/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9256\n",
            "Epoch 358/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9226\n",
            "Epoch 359/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9137\n",
            "Epoch 360/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9345\n",
            "Epoch 361/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9048\n",
            "Epoch 362/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9256\n",
            "Epoch 363/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9137\n",
            "Epoch 364/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9256\n",
            "Epoch 365/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9196\n",
            "Epoch 366/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9048\n",
            "Epoch 367/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9315\n",
            "Epoch 368/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9256\n",
            "Epoch 369/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9137\n",
            "Epoch 370/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9286\n",
            "Epoch 371/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9286\n",
            "Epoch 372/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9315\n",
            "Epoch 373/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9107\n",
            "Epoch 374/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9494\n",
            "Epoch 375/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9226\n",
            "Epoch 376/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9196\n",
            "Epoch 377/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9196\n",
            "Epoch 378/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9226\n",
            "Epoch 379/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9286\n",
            "Epoch 380/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9167\n",
            "Epoch 381/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9226\n",
            "Epoch 382/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9196\n",
            "Epoch 383/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9137\n",
            "Epoch 384/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9345\n",
            "Epoch 385/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9315\n",
            "Epoch 386/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9315\n",
            "Epoch 387/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9345\n",
            "Epoch 388/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9435\n",
            "Epoch 389/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9137\n",
            "Epoch 390/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9345\n",
            "Epoch 391/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9345\n",
            "Epoch 392/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9167\n",
            "Epoch 393/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9315\n",
            "Epoch 394/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9345\n",
            "Epoch 395/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9315\n",
            "Epoch 396/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9196\n",
            "Epoch 397/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9137\n",
            "Epoch 398/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9375\n",
            "Epoch 399/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9315\n",
            "Epoch 400/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9256\n",
            "Epoch 401/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9107\n",
            "Epoch 402/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9286\n",
            "Epoch 403/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9375\n",
            "Epoch 404/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9286\n",
            "Epoch 405/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9375\n",
            "Epoch 406/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9345\n",
            "Epoch 407/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9226\n",
            "Epoch 408/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9345\n",
            "Epoch 409/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9256\n",
            "Epoch 410/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9256\n",
            "Epoch 411/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.9375\n",
            "Epoch 412/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9286\n",
            "Epoch 413/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9286\n",
            "Epoch 414/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9226\n",
            "Epoch 415/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9226\n",
            "Epoch 416/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9226\n",
            "Epoch 417/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9464\n",
            "Epoch 418/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.9256\n",
            "Epoch 419/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9345\n",
            "Epoch 420/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9435\n",
            "Epoch 421/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9226\n",
            "Epoch 422/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.9226\n",
            "Epoch 423/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9375\n",
            "Epoch 424/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9286\n",
            "Epoch 425/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9315\n",
            "Epoch 426/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9435\n",
            "Epoch 427/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9286\n",
            "Epoch 428/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9226\n",
            "Epoch 429/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9226\n",
            "Epoch 430/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9375\n",
            "Epoch 431/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9256\n",
            "Epoch 432/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9256\n",
            "Epoch 433/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9405\n",
            "Epoch 434/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9256\n",
            "Epoch 435/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9405\n",
            "Epoch 436/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9435\n",
            "Epoch 437/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9435\n",
            "Epoch 438/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9345\n",
            "Epoch 439/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9226\n",
            "Epoch 440/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9226\n",
            "Epoch 441/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9345\n",
            "Epoch 442/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9464\n",
            "Epoch 443/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9315\n",
            "Epoch 444/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9345\n",
            "Epoch 445/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9375\n",
            "Epoch 446/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9315\n",
            "Epoch 447/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9256\n",
            "Epoch 448/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9554\n",
            "Epoch 449/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9435\n",
            "Epoch 450/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9405\n",
            "Epoch 451/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9494\n",
            "Epoch 452/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9226\n",
            "Epoch 453/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9167\n",
            "Epoch 454/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9256\n",
            "Epoch 455/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9226\n",
            "Epoch 456/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9524\n",
            "Epoch 457/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9435\n",
            "Epoch 458/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9137\n",
            "Epoch 459/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9405\n",
            "Epoch 460/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9107\n",
            "Epoch 461/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9315\n",
            "Epoch 462/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9405\n",
            "Epoch 463/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9494\n",
            "Epoch 464/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9554\n",
            "Epoch 465/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9345\n",
            "Epoch 466/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9226\n",
            "Epoch 467/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9524\n",
            "Epoch 468/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9524\n",
            "Epoch 469/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9583\n",
            "Epoch 470/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9524\n",
            "Epoch 471/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1768 - accuracy: 0.9405\n",
            "Epoch 472/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9464\n",
            "Epoch 473/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9494\n",
            "Epoch 474/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9345\n",
            "Epoch 475/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9464\n",
            "Epoch 476/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9405\n",
            "Epoch 477/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9375\n",
            "Epoch 478/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9226\n",
            "Epoch 479/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9494\n",
            "Epoch 480/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9554\n",
            "Epoch 481/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9435\n",
            "Epoch 482/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9554\n",
            "Epoch 483/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1816 - accuracy: 0.9464\n",
            "Epoch 484/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9375\n",
            "Epoch 485/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9494\n",
            "Epoch 486/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9673\n",
            "Epoch 487/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9345\n",
            "Epoch 488/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9494\n",
            "Epoch 489/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9375\n",
            "Epoch 490/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9643\n",
            "Epoch 491/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9524\n",
            "Epoch 492/500\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9286\n",
            "Epoch 493/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9435\n",
            "Epoch 494/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9405\n",
            "Epoch 495/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9375\n",
            "Epoch 496/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9286\n",
            "Epoch 497/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9464\n",
            "Epoch 498/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9435\n",
            "Epoch 499/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9435\n",
            "Epoch 500/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9435\n",
            "--Evaluate model--\n",
            "13/13 - 0s - loss: 1.1530 - accuracy: 0.6508\n",
            "Model Loss:    1.15\n",
            "Model Accuray: 65.1%\n",
            "\n",
            "Predicted CHD Diagnose Rate: 0.94%     | Actual outcome:  Has CHD\n",
            "Predicted CHD Diagnose Rate: 98.87%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 32.53%     | Actual outcome:  Has CHD\n",
            "Predicted CHD Diagnose Rate: 30.44%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 0.08%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 1.38%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 33.76%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 9.22%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 100.00%     | Actual outcome:  no CHD\n",
            "Predicted CHD Diagnose Rate: 98.32%     | Actual outcome:  Has CHD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHGA5qFu-Jd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}